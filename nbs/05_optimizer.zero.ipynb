{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Redundancy Optimizer\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp optim.zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer, SGD\n",
    "\n",
    "from fastgoose.mpu.parallel import ParallelState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ZeRO(Optimizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        optim: Optimizer,\n",
    "        parallel_state: ParallelState,\n",
    "        defaults: dict = dict()\n",
    "    ):\n",
    "        super().__init__(params, defaults=defaults)\n",
    "        self.optim = optim\n",
    "        self.parallel_state = parallel_state\n",
    "        \n",
    "        self._init_local_optimizer()\n",
    "    \n",
    "    @property\n",
    "    def rank(self) -> int:\n",
    "        \"\"\"Return the rank of the current process.\"\"\"\n",
    "        return self.parallel_state.rank\n",
    "\n",
    "    @property\n",
    "    def world_size(self) -> int:\n",
    "        \"\"\"Return the number of processes participating in the job.\"\"\"\n",
    "        return self.parallel_state.world_size\n",
    "    \n",
    "    def _init_local_optimizer(self):\n",
    "        \"\"\"Initialize the local optimizer for the current rank.\"\"\"\n",
    "        rank = self.parallel_state.rank\n",
    "        params_per_rank = self.param_to_ranks()\n",
    "        param_of_current_rank = params_per_rank[rank]\n",
    "        self.local_optim = self.optim(param_of_current_rank, **self.defaults)\n",
    "    \n",
    "    def param_to_ranks(self) -> List[List[torch.Tensor]]:\n",
    "        \"\"\"Partition the parameters across the ranks.\"\"\"\n",
    "        for param_group in self.param_groups:\n",
    "            params_per_rank = self._partrition_paramaters_per_rank(param_group['params'])\n",
    "            return params_per_rank\n",
    "    \n",
    "    def _partrition_paramaters_per_rank(self, param_list) -> List[List[torch.Tensor]]:\n",
    "        \"\"\"Partition the parameters across the ranks.\"\"\"\n",
    "        numel_per_rank = [0 for _ in range(self.world_size)]\n",
    "        param_per_rank = [[] for _ in range(self.world_size)]\n",
    "        sorted_params = sorted(param_list, key=lambda x: x.numel(), reverse=True)\n",
    "        \n",
    "        for param in sorted_params:\n",
    "            rank = numel_per_rank.index(min(numel_per_rank))\n",
    "            numel_per_rank[rank] += param.numel()\n",
    "            param_per_rank[rank].append(param)\n",
    "        \n",
    "        return param_per_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(10, 10), nn.Linear(10, 10), nn.Linear(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_state = ParallelState(\n",
    "    tensor_parallel_size=2,\n",
    "    pipeline_parallel_size=4,\n",
    "    data_parallel_size=2,\n",
    "    world_size=16,\n",
    "    master_addr='localhost',\n",
    "    master_port=1234,\n",
    "    backend='nccl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_optimizer = ZeRO(model.parameters(), SGD, parallel_state=parallel_state, defaults={\"lr\": 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Parameter containing:\n",
       "  tensor([[ 0.0130, -0.2725,  0.1036, -0.2668, -0.0091, -0.1629,  0.0786, -0.1901,\n",
       "           -0.3070, -0.1132],\n",
       "          [-0.1940, -0.1832,  0.0139, -0.2267,  0.1815,  0.0156,  0.1376, -0.1220,\n",
       "           -0.1053,  0.0153],\n",
       "          [-0.0230, -0.2597,  0.1408, -0.0549, -0.1920, -0.0295, -0.2258, -0.2049,\n",
       "           -0.2305, -0.1301],\n",
       "          [-0.1884, -0.0528,  0.2176,  0.1626, -0.1197,  0.0237,  0.2957,  0.2946,\n",
       "            0.0591,  0.0059],\n",
       "          [-0.0655,  0.2768, -0.2711, -0.0580, -0.0561,  0.1394, -0.2170,  0.0078,\n",
       "           -0.1938,  0.2141],\n",
       "          [-0.1597,  0.0672,  0.0383, -0.2570, -0.1070, -0.2008,  0.1370, -0.2971,\n",
       "           -0.2826,  0.1393],\n",
       "          [ 0.2414, -0.1806,  0.0412, -0.0528,  0.0788,  0.2607, -0.1962,  0.1306,\n",
       "           -0.1389, -0.0235],\n",
       "          [-0.2913, -0.2463, -0.1943,  0.1044, -0.1574,  0.1706, -0.1575,  0.0664,\n",
       "           -0.2615,  0.1355],\n",
       "          [ 0.1876,  0.1476,  0.1083, -0.1976, -0.1943, -0.0501, -0.0293,  0.2357,\n",
       "           -0.2374,  0.3038],\n",
       "          [ 0.2299, -0.0226, -0.0635,  0.1982, -0.0004,  0.2940,  0.1495,  0.2933,\n",
       "            0.0720, -0.2539]], requires_grad=True)],\n",
       " [Parameter containing:\n",
       "  tensor([[-0.2027, -0.1298, -0.1169, -0.2659,  0.1372, -0.1352,  0.1100, -0.0007,\n",
       "            0.2249, -0.0268],\n",
       "          [-0.2577, -0.2141,  0.0227, -0.0214,  0.0553,  0.2428,  0.0304,  0.0374,\n",
       "           -0.2354, -0.0617],\n",
       "          [-0.1687, -0.0761, -0.2127, -0.0903,  0.0335,  0.0277, -0.2107, -0.2694,\n",
       "           -0.0859, -0.0667],\n",
       "          [-0.0900, -0.0079,  0.2971,  0.1087, -0.0836,  0.1249, -0.2392,  0.2029,\n",
       "           -0.2770, -0.1055],\n",
       "          [ 0.0270, -0.2830, -0.2690,  0.2309, -0.1878, -0.0338, -0.0546, -0.2932,\n",
       "           -0.1599, -0.3146],\n",
       "          [-0.2747, -0.2000,  0.1007,  0.0959, -0.1047, -0.1951,  0.1753,  0.1627,\n",
       "           -0.3094, -0.2620],\n",
       "          [-0.1514,  0.1660,  0.2812, -0.2357,  0.2329,  0.1925, -0.0406,  0.2462,\n",
       "           -0.1473, -0.1108],\n",
       "          [ 0.0245, -0.0315, -0.3152, -0.1642, -0.2979,  0.0590,  0.3044,  0.1698,\n",
       "            0.1552,  0.2659],\n",
       "          [ 0.3014, -0.0183, -0.1774, -0.0537, -0.2208, -0.1520, -0.2171, -0.2511,\n",
       "            0.2674,  0.1107],\n",
       "          [ 0.2755, -0.1081,  0.2982,  0.1934,  0.0463, -0.1177, -0.1503,  0.2411,\n",
       "           -0.2518, -0.0094]], requires_grad=True)],\n",
       " [Parameter containing:\n",
       "  tensor([[ 0.0275, -0.2228, -0.0719, -0.1819, -0.0196, -0.0662,  0.0849,  0.2394,\n",
       "           -0.0298, -0.2203],\n",
       "          [-0.2494,  0.0644,  0.0165, -0.2868, -0.3107,  0.1773,  0.0743,  0.1218,\n",
       "            0.1918,  0.2397],\n",
       "          [ 0.2195,  0.0295, -0.1575,  0.0528,  0.1073, -0.1380, -0.0946,  0.3054,\n",
       "           -0.1117,  0.0786],\n",
       "          [ 0.1032, -0.1360, -0.0871, -0.2370,  0.2755, -0.1859, -0.2788,  0.0720,\n",
       "            0.3034, -0.1249],\n",
       "          [ 0.2762,  0.2287, -0.0461, -0.3005,  0.0508,  0.1901,  0.0863, -0.1051,\n",
       "            0.2342, -0.2913],\n",
       "          [-0.1203,  0.2206, -0.0918, -0.0749, -0.1033,  0.2646,  0.2640, -0.1176,\n",
       "            0.3044,  0.0514],\n",
       "          [ 0.3066, -0.2429,  0.1898, -0.2937,  0.0178, -0.1783,  0.1133,  0.0279,\n",
       "           -0.1562,  0.1747],\n",
       "          [-0.0748,  0.0769, -0.2731,  0.2477, -0.0970,  0.0250,  0.1031, -0.1123,\n",
       "            0.1328,  0.0501],\n",
       "          [ 0.0642, -0.0884,  0.1820, -0.0929,  0.1765, -0.1029,  0.0636, -0.1460,\n",
       "           -0.2204, -0.0914],\n",
       "          [-0.1869,  0.1547, -0.2101,  0.1295, -0.2523, -0.0061, -0.2650, -0.2122,\n",
       "           -0.1202,  0.1792]], requires_grad=True)],\n",
       " [Parameter containing:\n",
       "  tensor([-0.1074, -0.1740,  0.3055,  0.1819,  0.0459,  0.2641,  0.2199,  0.2591,\n",
       "           0.2479, -0.2629], requires_grad=True)],\n",
       " [Parameter containing:\n",
       "  tensor([ 0.2778,  0.1264, -0.0217, -0.2278, -0.1505, -0.1127,  0.1139,  0.2140,\n",
       "           0.2555, -0.2134], requires_grad=True)],\n",
       " [Parameter containing:\n",
       "  tensor([ 0.0649,  0.1984,  0.0593,  0.1803, -0.1958,  0.2377,  0.0450,  0.1356,\n",
       "          -0.0312, -0.1837], requires_grad=True)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_optimizer.param_to_ranks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
